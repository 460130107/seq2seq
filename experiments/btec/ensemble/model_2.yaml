
dropout_rate: 0.5
cell_size: 256
embedding_size: 256
layers: 2
bidir: True
use_lstm: True
steps_per_checkpoint: 1000
steps_per_eval: 2000
max_steps: 50000
optimizer: 'adam'

data_dir: experiments/btec/data
model_dir: experiments/btec/ensemble/model_2
log_file: experiments/btec/ensemble/model_2/log.txt

encoders:
  - name: fr
    vocab_size: 9218

decoder:
    name: en
    vocab_size: 7186
