
learning_rate_decay_factor: 0.95
dropout_rate: 0.5
cell_size: 256
embedding_size: 256
layers: 2
bidir: True
use_lstm: True
data_dir: experiments/btec/pre-training/data
train_prefix: btec

model_dir: experiments/btec/pre-training/models/btec
log_file: experiments/btec/pre-training/models/btec/log.txt
checkpoints: experiments/btec/pre-training/models/news/checkpoints/best

encoders:
  - name: fr
    vocab_size: 9218
    buckets: [ 5, 10, 20, 51]

decoder:
    name: en
    vocab_size: 7186
    buckets: [10, 15, 25, 51]
