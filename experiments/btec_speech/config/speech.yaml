# BTEC French ASR attempt

learning_rate_decay_factor: 0.95
dropout_rate: 0.5
cell_size: 256
embedding_size: 256
layers: 2
bidir: True
use_lstm: True
data_dir: data/btec

model_dir: models/speech
log_file: models/speech/log.txt

encoders:
  - name: feats
    embedding_size: 123
    vocab_size: 0
    buckets: [120, 180, 220, 260, 310, 360, 420, 600]
    layers: 3
    time_pooling: [2, 2]
    binary: True
    # TODO: try with those
    # attention_filters: 1
    # attention_filter_length: 10
    # attention_window_size: 20

decoder:
    name: fr
    vocab_size: 9218
    buckets: [  6,   8,  10,  12,  14,  16,  18,  23]
