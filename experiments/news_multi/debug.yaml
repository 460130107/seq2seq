
learning_rate_decay_factor: 0.95
dropout_rate: 0.0
cell_size: 128
embedding_size: 128
layers: 1
bidir: False
use_lstm: False
data_dir: experiments/news/data
steps_per_checkpoint: 200
steps_per_eval: 1000

model_dir: experiments/news/model
log_file: experiments/news/model/log.txt

encoders:
  - name: fr
    vocab_size: 30000
    buckets: [ 5, 10, 20, 50]
  - name: de
    vocab_size: 30000
    buckets: [ 5, 10, 20, 50]

decoder:
    name: en
    vocab_size: 30000
    buckets: [10, 15, 25, 50]
