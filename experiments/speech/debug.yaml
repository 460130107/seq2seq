
learning_rate_decay_factor: 0.95
dropout_rate: 0.5
cell_size: 128
embedding_size: 128
layers: 1
bidir: False
use_lstm: False
data_dir: experiments/speech/data
steps_per_checkpoint: 50
steps_per_eval: 1000
max_steps: 50000

model_dir: experiments/speech/debug
log_file: null
max_output_len: 20

encoders:
  - name: feats
    embedding_size: 123
    vocab_size: 0
    layers: 3
    time_pooling: [2, 2]
    pooling_avg: True
    binary: True
    attention_filters: 1
    attention_filter_length: 22
    # attention_window_size: 20

decoder:
    name: en
    vocab_size: 7186
