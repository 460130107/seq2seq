# Really small model on BTEC for debugging purposes

dropout_rate: 0.0
cell_size: 64
attn_size: 64
embedding_size: 32

layers: 1
bidir: True
use_lstm: False
steps_per_checkpoint: 1000
steps_per_eval: 1000
max_epochs: 25
max_output_len: 25
max_input_len: 25
weight_scale: 0.1

data_dir: data/btec
model_dir: models/debug
log_file: models/debug/log.txt
batch_size: 32
dev_prefix: dev
max_dev_size: 500

# optimizer: 'adam'
max_gradient_norm: 1.0
optimizer: 'sgd'
learning_rate: 0.5
loss_function: 'xent'    # XENT has 40.68 BLEU, 38.01 TER
baseline_steps: 2000
reinforce_baseline: True
reinforce_reward: sentence_bleu
score_function: corpus_bleu

batch_mode: 'standard'
read_ahead: 10

encoders:
  - name: fr

decoder:
    name: en
